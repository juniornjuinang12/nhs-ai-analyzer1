import streamlit as st
import os
import json
from dotenv import load_dotenv

# === Importer ton code existant ===
from src.scraper import extract_pdf_links
from src.downloader import download_pdf
from src.extractor import extract_text_from_pdf
from src.analyzer import analyze_text

load_dotenv()

st.set_page_config(page_title="NHS AI Analyzer", layout="centered")
st.title("ü§ñ NHS AI Analyzer")
st.markdown("Analyse automatique des rapports PDF des h√¥pitaux avec IA.")

# === Interface utilisateur ===
with st.form("url_form"):
    url = st.text_input("üîó URL d‚Äôun h√¥pital (ex: https://www.nhshospital.org/...)")
    submitted = st.form_submit_button("Lancer l'analyse")

if submitted and url:
    with st.spinner("üîç Scraping des PDFs..."):
        pdfs = extract_pdf_links(url)

    if pdfs:
        st.success(f"{len(pdfs)} PDF(s) trouv√©s.")
        report = []

        for i, pdf_url in enumerate(pdfs[:3]):
            with st.spinner(f"T√©l√©chargement du PDF {i+1}..."):
                download_pdf(pdf_url)

        with st.spinner("üîé Extraction et analyse IA en cours..."):
            for filename in os.listdir("pdfs")[:3]:
                if filename.endswith(".pdf"):
                    filepath = os.path.join("pdfs", filename)
                    text = extract_text_from_pdf(filepath)
                    summary = analyze_text(text)
                    report.append({
                        "filename": filename,
                        "summary": summary
                    })

        st.success("‚úÖ Analyse termin√©e")
        st.json(report)

        # Option de t√©l√©chargement
        st.download_button("üì• T√©l√©charger le rapport JSON", json.dumps(report, indent=2, ensure_ascii=False), "report.json")
    else:
        st.warning("Aucun PDF trouv√© sur cette page.")
